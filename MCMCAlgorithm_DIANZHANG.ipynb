{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithm: Metropolis-Hasting Algorithm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on my coding, the Metropolis-Hasting Algorithm can be saparater to 2 parts:     \n",
    "1.__init__  \n",
    "In this part, we need input \"rho\" the target distribution of the parameter and \"seed\" the random see to generater u which is the random variable used to deciding whether to reject the update the paramteter during the prediction.  \n",
    "2.predict  \n",
    "In this part, we need input \"theta0\" the initial state of the parameter which can be the output of the previous prediction, \"qProb\" the function used to calculate the probability of the proposal value of the parameter with given the previous value of the parameter, \"qSamp\" the function used to draw the proposal value of the parameter from the proposal distribution of the sample with given the previous value of the parameter and \"epoch\" the number of round of prediction of the parameter with the Metropolis-Hasting Algorithm.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Callable\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class MHMC:  \n",
    "    def __init__(\n",
    "    self, \n",
    "    rho: Callable, # the target distribution of the parameter\n",
    "    seed=123 # setting the random seed of the distribution\n",
    "    ) -> None:\n",
    "        np.random.seed(seed)\n",
    "        self.rho = rho\n",
    "\n",
    "    def predict(\n",
    "        self,\n",
    "        theta0: List[int], # the initial value of the parameter\n",
    "        qProb: Callable, # probability of the proposal distribution of the parameter\n",
    "        qSamp: Callable, # draw the sample with the proposal distribution\n",
    "        epoch: int # trian the MCMC for n epoch\n",
    "    ) -> List[int]:\n",
    "        self.qProb = qProb\n",
    "        self.qSamp = qSamp\n",
    "        theta_n = theta0\n",
    "        for i in range(0, epoch):\n",
    "            # Updating the parameter from the proposal disribution\n",
    "            theta_nPlus1 = self.qSamp(theta_n)\n",
    "            alpha = min(1, (self.rho(theta_nPlus1)*self.qProb(theta_nPlus1,theta_n))/(self.rho(theta_n)*self.qProb(theta_n,theta_nPlus1)))\n",
    "            # Deciding whether to reject the update of the parameter\n",
    "            u = np.random.default_rng().uniform(0, 1, 1)[0]\n",
    "            if(alpha>=u):\n",
    "                theta_n = theta_nPlus1\n",
    "            else:\n",
    "                pass\n",
    "        return theta_n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alogrithm: Hamiltonian Monte Carlo Alforithm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since  \n",
    "$$U(\\theta) = -log(\\rho(\\theta)),$$\n",
    "where $\\rho(\\theta)$ is the probability distribution of the parameter $\\theta$.  \n",
    "Then  \n",
    "$$\\frac{dU(\\theta)}{d\\theta} = -\\frac{\\rho'(\\theta)}{\\rho(\\theta)}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Callable\n",
    "import numpy as np\n",
    "class HMC:\n",
    "    def __init__(\n",
    "        self,\n",
    "        rho: Callable, # the target distribution of the parameter\n",
    "        drho_dtheta: List[Callable], # the derivative of the target distribution\n",
    "    ) -> None:\n",
    "        self.rho = rho\n",
    "        self.drho_dtheta = drho_dtheta\n",
    "\n",
    "    def U(\n",
    "        self,\n",
    "        theta: List[float]\n",
    "    ) -> float: # the potential energy function: U(theta) = -log(probability distribution of theta)\n",
    "        return - np.log(self.rho(theta))\n",
    "    \n",
    "    def dU_dtheta(\n",
    "        self,\n",
    "        theta: List[float]\n",
    "    ) -> float: # the derivative of the potential energy function\n",
    "    \n",
    "        return [-(self.rho(theta))/(self.drho_dtheta[i](theta)) for i in range(len(self.drho_dtheta))]\n",
    "\n",
    "\n",
    "    def predict(\n",
    "        self,\n",
    "        theta0: List[float], # initial value of the parameter\n",
    "        lr: float, # learning rate\n",
    "        L: int, # the number of leapfrog steps in the trajectory\n",
    "        epoch: int # trian the MCMC for n epoch\n",
    "    ):\n",
    "        theta_n = theta0\n",
    "        for _ in range(0, epoch):\n",
    "            theta_nPlus1 = theta_n\n",
    "            # the ”positions” which are independent standard normal variables\n",
    "            p_n = np.random.default_rng().normal(0, 1, len(theta_n))\n",
    "            p_nPlus1 = p_n\n",
    "            # At the beginning, take a half step for momentum.\n",
    "            p_nPlus1 = p_nPlus1 - [lr*i/2 for i in self.dU_dtheta(theta_nPlus1)]\n",
    "            for i in range(0,L):\n",
    "                # Take a full step for the position\n",
    "                theta_nPlus1 = theta_nPlus1 + lr*p_nPlus1\n",
    "                # Unless at the end of the trajectory, take a full step for the momentum\n",
    "                p_nPlus1 = (p_nPlus1 - [lr*i for i in self.dU_dtheta(theta_nPlus1)]) if (i<(L-1)) else p_nPlus1\n",
    "            # At the end, take a half step for momentum.\n",
    "            p_nPlus1 = p_nPlus1 - [lr*i for i in self.dU_dtheta(theta_nPlus1)]\n",
    "            # To make the proposal symmetric, negate momentum at end of trajectory\n",
    "            p_nPlus1 = -p_nPlus1\n",
    "            # At start and end of trajectory, evaluate potential and kinetic energies\n",
    "            u_n = self.U(theta_n)\n",
    "            k_n = 0\n",
    "            for pValue in p_n:\n",
    "                k_n += pValue**2\n",
    "            k_n /= 2\n",
    "            u_nPlus1 = self.U(theta_nPlus1)\n",
    "            k_nPlus1= 0\n",
    "            for pValue in p_nPlus1:\n",
    "                k_nPlus1 += pValue**2\n",
    "            k_nPlus1 /= 2\n",
    "            # At end of trajectory deciding whether accept or reject the state , returning either the position at the end of the trajectory or the initial position\n",
    "            alpha = np.exp(u_n-u_nPlus1+k_n-k_nPlus1)\n",
    "            u = np.random.default_rng().uniform(0, 1, 1)[0]\n",
    "            if(alpha>u):\n",
    "                theta_n = theta_nPlus1\n",
    "            else:\n",
    "                pass\n",
    "        return theta_n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gaussian Distribution"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let $\\left( \\begin{array}{c} x_1 \\\\ x_2 \\end{array}\\right)$ $\\sim$ $N(\\left( \\begin{array}{c} \\mu_1 \\\\ \\mu_2 \\end{array}\\right),\\left( \\begin{array}{cc} 1 & 0 \\\\ 0 & 1 \\end{array}\\right))$.  \n",
    "Then  \n",
    "$$f(x_1, x_2| \\mu_1, \\mu_2) = \\prod_{i=1}^2 \\frac{exp(-\\frac{(x_i - \\mu_i)^2}{2})}{\\sqrt{2\\pi}}$$\n",
    "If we have data $data:= \\{(x_{1,i}, x_{2, i})\\}_{i = 1, 2, 3, ..., n}$ from the distribution $N(\\left( \\begin{array}{c} 2 \\\\ 2 \\end{array}\\right),\\left( \\begin{array}{cc} 1 & 0 \\\\ 0 & 1 \\end{array}\\right))$.  \n",
    "Then the likelihood function of the data above is  \n",
    "$$L(\\mu_1, \\mu_2) = \\prod_{i=1}^n f(x_{1, i}, x_{2, i}| \\mu_1, \\mu_2)$$\n",
    "By partial derivating $L$ respect to $\\mu_i$\n",
    "$$\\frac{\\partial L(\\mu_1, \\mu_2)}{\\mu_i} = (x_i - \\mu_i) \\prod_{i=1}^n f(x_{1, i}, x_{2, i}| \\mu_1, \\mu_2)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class Likelihood_Gaussian:\n",
    "    def __init__(self, Dim:int, Dataset: List[List[float]]) -> None:\n",
    "        self.Dim = Dim\n",
    "        self.Dataset = Dataset\n",
    "    \n",
    "    def f(self, x: List[float], mu: List[float]) -> float:\n",
    "        res = 1\n",
    "        for i in  range(0, self.Dim):\n",
    "            res *= (np.exp(-((x[i]+mu[i])**2)/2))/((2*np.pi)**0.5)\n",
    "        return res\n",
    "\n",
    "    def L(self, mu: List[float]) -> List[float]:\n",
    "        res = 1\n",
    "        for i in range(len(self.Dataset)):\n",
    "            res *= self.f(self.Dataset[i], mu)\n",
    "        return res\n",
    "    \n",
    "    def dLdmu_i(self, mu: List[float]) -> List[float]:\n",
    "        res = 1\n",
    "        for k in range(len(self.Dataset)):\n",
    "            res *= self.f(self.Dataset[k], mu)\n",
    "        for k in range(len(self.Dataset)):\n",
    "            res *= (self.Dataset[k][self.i]-mu[self.i])\n",
    "        return res\n",
    "\n",
    "    def dLdmu_iGen(self, i: int) -> Callable:\n",
    "        self.i = i\n",
    "        return self.dLdmu_i"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Preparing data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating 100 datapoints from the distribution $N(\\left( \\begin{array}{c} 2 \\\\ 2 \\end{array}\\right),\\left( \\begin{array}{cc} 1 & 0 \\\\ 0 & 1 \\end{array}\\right))$.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset = []\n",
    "for _ in range(0,100):\n",
    "    Dataset.append(list(np.random.default_rng().normal(8, 1, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/PyTorchTest/lib/python3.6/site-packages/ipykernel_launcher.py:23: RuntimeWarning: invalid value encountered in double_scalars\n",
      "/opt/anaconda3/envs/PyTorchTest/lib/python3.6/site-packages/ipykernel_launcher.py:16: RuntimeWarning: divide by zero encountered in log\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0, 0]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Likeli = Likelihood_Gaussian(Dim=2, Dataset=Dataset)\n",
    "Hamiltonian = HMC(rho=Likeli.L, drho_dtheta=[Likeli.dLdmu_iGen(i) for i in range(0, 2)])\n",
    "Hamiltonian.predict(\n",
    "    [0, 0],\n",
    "    1e-2,\n",
    "    5,\n",
    "    1000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorchTest",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "02dcf9bc5ed1dd7ded51c9e5ccdbc2599fa9c2201bc68eb25d7cf0d1d72d0607"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
