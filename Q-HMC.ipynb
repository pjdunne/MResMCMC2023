{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hamiltonian Monte Carlo"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Theory\n",
    "With reference to [Stan Reference Manual](https://mc-stan.org/docs/reference-manual/hamiltonian-monte-carlo.html).\n",
    "\n",
    "\n",
    "\n",
    "- The goal is to draw samples from a target distribution $p(\\theta)$ for parameters $\\theta$. (Dian uses $\\rho(\\theta)$ for the probability distribution)\n",
    "\n",
    "- HMC introduces auxilary momentum variables $\\rho$, this auxilary density $\\rho$ is a multivariate normal and is independent of $\\theta$.\n",
    "\n",
    "    - $\\rho \\sim MultiNormal(\\underline{0}, M)$, where $M$ is the [Euclidean metric](https://mathworld.wolfram.com/EuclideanMetric.html).\n",
    "\n",
    "        - eg. a 2D Gaussian $p(\\textbf{x}) = \\mathcal{N}(\\textbf{x};\\begin{bmatrix} 0 \\\\ 0 \\end{bmatrix},\\begin{bmatrix} 1 & 0.98 \\\\ 0.98 & 1 \\end{bmatrix})$\n",
    "\n",
    "- The Hamiltonian $H(\\rho,\\theta)= kinetic \\ energy + potential \\ energy$\n",
    "\n",
    "    - $kinetic \\ energy = K (\\rho \\mid \\theta) = - \\log p(\\rho \\mid \\theta)$\n",
    "\n",
    "    - $potential \\ energy = U(\\theta) = -\\log p(\\theta)$\n",
    "\n",
    "    - $\\frac{d\\theta}{dt} = -\\frac{\\partial T}{\\partial \\rho}$\n",
    "    \n",
    "    - $\\frac{d\\rho}{dt} = -\\frac{\\partial U}{\\partial \\theta}$\n",
    "\n",
    "**Leapfrog integrator**\n",
    "\n",
    "For small time inteval $\\epsilon$, it updates the $\\rho$ and $\\theta$ as follows:\n",
    "- $$\\rho \\leftarrow \\rho - \\frac{\\epsilon}{2} \\frac{\\partial U}{\\partial \\theta}$$\n",
    "- $$\\theta \\leftarrow \\theta + \\epsilon M^{-1} \\rho$$\n",
    "- $$\\rho \\leftarrow \\rho - \\frac{\\epsilon}{2} \\frac{\\partial U}{\\partial \\theta}$$\n",
    "\n",
    "After the orbit is integrated for a while, a new proposed sample is generated, and accepted or rejected,\n",
    "then a new random momentum is generated and the procedure repeated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters\n",
    "\n",
    "With reference to [Stan Reference Manual](https://mc-stan.org/docs/reference-manual/hmc-algorithm-parameters.html)\n",
    "\n",
    "The Hamiltonian Monte Carlo algorithm has three parameters which must be set,\n",
    "\n",
    "- discretization time $\\epsilon$\n",
    "- metric $M$\n",
    "- number of leapfrog steps taken $L$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$H(\\rho, \\theta) =  U(\\theta) + K(\\rho)$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Pseudo code**\n",
    "Copying from [HMC Handbook, Chapter 5, Page 125](https://www.mcmchandbook.net/HandbookChapter5.pdf)\n",
    "\n",
    "At which $q$ is the same as the \"postition\" $\\theta$, and $p$ is the same as the \"momentum\" $\\rho$\n",
    "\n",
    "$\\rightarrow$ $H(q, p) = H(\\rho, \\theta) =  U(q) + K(p)$\n",
    "\n",
    "    HMC = function (U, grad_U, epsilon, L, current_q)\n",
    "    {\n",
    "        q = current_q\n",
    "        p = rnorm(length(q),0,1) # independent standard normal variates\n",
    "        current_p = p\n",
    "\n",
    "        # Make a half step for momentum at the beginning\n",
    "        p=p- epsilon * grad_U(q) / 2\n",
    "\n",
    "        # Alternate full steps for position and momentum\n",
    "\n",
    "        for (i in 1:L)\n",
    "        {\n",
    "            # Make a full step for the position\n",
    "            q=q+ epsilon * p\n",
    "            # Make a full step for the momentum, except at end of trajectory\n",
    "            if (i!=L)p=p- epsilon * grad_U(q)\n",
    "        }\n",
    "\n",
    "        # Make a half step for momentum at the end.\n",
    "        p=p- epsilon * grad_U(q) / 2\n",
    "        # Negate momentum at end of trajectory to make the proposal symmetric\n",
    "        p = -p\n",
    "\n",
    "        # Evaluate potential and kinetic energies at start and end of trajectory\n",
    "        current_U = U(current_q)\n",
    "        current_K = sum(current_pˆ2) / 2\n",
    "        proposed_U = U(q)\n",
    "        proposed_K = sum(pˆ2) / 2\n",
    "\n",
    "        # Accept or reject the state at end of trajectory, returning either\n",
    "        # the position at the end of the trajectory or the initial position\n",
    "\n",
    "        if (runif(1) < exp(current_U-proposed_U+current_K-proposed_K))\n",
    "        {\n",
    "            return (q) # accept\n",
    "        }\n",
    "        else\n",
    "        {\n",
    "            return (current_q) # reject\n",
    "        }\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def HMC(epoch, L, epsilon, U, grad_U, current_theta):\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    Hamiltonian Monte Carlo algorithm\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    epoch: number of iteration of the algorithm\n",
    "    L: number of steps of leap frog\n",
    "    epsilon: step size for discrete approximation\n",
    "    U: potential energy\n",
    "    grad_U: derivative of potential energy\n",
    "    current_theta: the current 'position'\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    theta: if accpeted\n",
    "    current_theta: if rejected\n",
    "\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    theta = current_theta\n",
    "    rho = np.random.normal(loc = 0, scale = 1, size= len(theta)) # sample random momentum\n",
    "    current_rho = rho\n",
    "    \n",
    "    # make a half step for momentum at the beginning\n",
    "    rho = rho - epsilon * grad_U(theta) / 2 \n",
    "\n",
    "    # alternate full steps for position and momentum\n",
    "    for i in range(1, L):\n",
    "\n",
    "        #make a full step for the position\n",
    "        theta = theta + epsilon * rho\n",
    "\n",
    "        #make a full step for the momentum, except at end of trajectory\n",
    "        if (i != L):\n",
    "            rho = rho - epsilon * grad_U(theta)\n",
    "    \n",
    "    # make a half step for momentum at the end\n",
    "    rho = rho - epsilon * grad_U(theta) / 2\n",
    "\n",
    "    # Negate momentum at end of trajectory to make the proposal symmetric\n",
    "    rho = -rho\n",
    "\n",
    "    # Evaluate potential and kinetic energies at start and end of trajectory (K kinetic energy, U potential energy)\n",
    "    current_U = U(current_theta)\n",
    "    current_K = sum(current_rho**2) / 2\n",
    "    proposed_U = U(theta)\n",
    "    proposed_K = sum(rho**2) / 2\n",
    "\n",
    "    # Accept or reject the state at end of trajectory, returning either\n",
    "    # the position at the end of the trajectory or the initial position\n",
    "\n",
    "    if (np.random.uniform(0, 1) < np.exp(current_U - proposed_U + current_K - proposed_K)):\n",
    "        return (theta) # accept\n",
    "    else:\n",
    "        return (current_theta) # reject"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Likelihood\n",
    "\n",
    "Borrowing from 'MCMCAlgorithm_DIANZHANG.ipynb'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Callable\n",
    "\n",
    "class Likelihood_Gaussian:\n",
    "    def __init__(self, Dim:int, Dataset: List[List[float]]) -> None:\n",
    "        self.Dim = Dim\n",
    "        self.Dataset = Dataset\n",
    "    \n",
    "    def f(self, x: List[float], mu: List[float]) -> float:\n",
    "        res = 1\n",
    "        for i in  range(0, self.Dim):\n",
    "            res *= (np.exp(-((x[i]-mu[i])**2)/2))/(np.sqrt(2*np.pi))\n",
    "        return res\n",
    "\n",
    "    def L(self, mu: List[float]) -> float:\n",
    "        res = 1\n",
    "        for i in range(len(self.Dataset)):\n",
    "            res *= self.f(self.Dataset[i], mu)\n",
    "        return res\n",
    "    \n",
    "    def dLdmu(self, mu: List[float]) -> List[float]:\n",
    "        res = self.L(mu)\n",
    "        Res = []\n",
    "        for i in range(len(mu)):\n",
    "            subres = res\n",
    "            for k in range(len(self.Dataset)):\n",
    "                subres *= (self.Dataset[k][i]-mu[i])\n",
    "            Res.append(subres)\n",
    "        return Res"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data: $\\mathcal{N}(\\begin{bmatrix} 2 \\\\ 2 \\end{bmatrix}, \\begin{bmatrix} 1 & 0 \\\\ 0 & 1 \\end{bmatrix})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import gaussian_kde\n",
    "\n",
    "Dataset = []\n",
    "for _ in range(0,40):\n",
    "    Dataset.append(list(np.random.default_rng().normal(2, 1, 2)))\n",
    "\n",
    "x1 = [p[0] for p in Dataset]\n",
    "x2 = [p[1] for p in Dataset]\n",
    "x1x2 = np.vstack([x1,x2])\n",
    "z = gaussian_kde(x1x2)(x1x2)\n",
    "plt.scatter(x1, x2, c=z, s=100)\n",
    "plt.xlabel(\"$x_1$\")\n",
    "plt.ylabel(\"$x_2$\")\n",
    "plt.title(\"Generated Data\")\n",
    "plt.show()\n",
    "\n",
    "Likeli = Likelihood_Gaussian(Dim=2, Dataset=Dataset)\n",
    "Grid = np.linspace(0, 4, 100)\n",
    "x = []\n",
    "y = []\n",
    "z = []\n",
    "r = len(Grid)\n",
    "for g in Grid:\n",
    "    y += list(Grid)\n",
    "    x += [g]*r\n",
    "    z += [Likeli.L([g, k]) for k in Grid]\n",
    "fig = plt.figure(figsize=(8, 8), facecolor=\"white\")\n",
    "Gau = fig.add_subplot(projection=\"3d\")\n",
    "Gau.plot(x, y, z, alpha=0.7)\n",
    "Gau.set_xlabel(\"$\\mu_1$\", fontsize=15)\n",
    "Gau.set_ylabel(\"$\\mu_2$\", fontsize=15)\n",
    "Gau.set_zlabel(\"$L(\\mu_1, \\mu_2| {(x_{1,i}, x_{2,i})})_{i \\in \\{1,..,40\\}}$\", fontsize=11)\n",
    "Gau.set_title(\"Likelihood function of Gaussian Distribution\", fontsize=20)\n",
    "fig.tight_layout()\n",
    "fig.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "U = Likeli.L\n",
    "grad_U = Likeli.dLdmu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HMC(epoch=100, L=20, epsilon=0.01, U=U, grad_U=grad_U, current_theta=[1,1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
